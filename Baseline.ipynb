{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fnavab/APS360-project/blob/main/Baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds9hU4qyMiYp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7ylfSVptRz-",
        "outputId": "d43eb2c8-d103-4515-cc98-8505c580a38c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#baseline\n",
        "#DORSA\n",
        "# Support Vector Machines\n",
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import svm , metrics\n",
        "#To do: check for the range of gamma and C\n",
        "#To do: find\n",
        "model=svm.SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
        "  decision_function_shape='ovr', degree=3, gamma=0.00001, kernel='rbf',\n",
        "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
        "  tol=0.001, verbose=False) \n",
        "#model = svm.SVC(gamma=0.00001)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "clothing_images=torch.load('/content/gdrive/My Drive/APS360 GROUP/1k-images.pt')\n",
        "\n",
        "#X = np.array([x.detach().numpy() for x,_ in clothing_images])\n",
        "#y= np.array([y.detach().numpy() for _,y in clothing_images])\n",
        "X = np.array([x.numpy() for x,_ in clothing_images])\n",
        "y= np.array([y.numpy() for _,y in clothing_images])\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "n_samples = len(clothing_images)\n",
        "#print(n_samples)\n",
        "X = X.reshape((n_samples, -1))\n",
        "\n",
        "#X = X.reshape(X.shape[1]*X.shape[2]*X.shape[3],X.shape[0]).T\n",
        "y = y.reshape(y.shape[0],)\n",
        "\n",
        "training_data, testing_data, training_labels, testing_labels = train_test_split(\n",
        " X, y, random_state=42)\n",
        "\n",
        "\n",
        "# Fit the model to our training data\n",
        "model.fit(training_data, training_labels)\n",
        "\n",
        "# Make predictions\n",
        "testing_predicted = model.predict(testing_data)\n",
        "#print(\"testing_data\",testing_data)\n",
        "print(\"testing_labels\",testing_labels)\n",
        "print(\"testing_predicted\",testing_predicted)\n",
        "#print(\"Confusion matrix:\\n%s\" % metrics.confusion_matrix(testing_data,testing_predicted))\n",
        "def accuracy_score(x,y):\n",
        "  score=0\n",
        "  for i in range(len(x)):\n",
        "    if x[i]==y[i]: \n",
        "      score+=1\n",
        "    \n",
        "  return score/len(x)\n",
        "score=accuracy_score(testing_predicted,testing_labels)\n",
        "print(\"SVM Test:\", score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJkYunPh47gd",
        "outputId": "b8fa5c47-0e48-4a7f-e113-62f0cdea71c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Fereshteh'\n",
        "#Data loading\n",
        "#mount googledrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt1ZmkOGfZTC"
      },
      "source": [
        "import torch\n",
        "\n",
        "clothing_images=torch.load('/content/gdrive/My Drive/Colab Notebooks/1k-images.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FXQ5ARI5y72"
      },
      "source": [
        "import random\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "import numpy as np\n",
        "import os\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "\n",
        "# clothing_images=torch.load('/content/gdrive/My Drive/Colab Notebooks/1k-images.pt')\n",
        "\n",
        "\n",
        "X = np.array([x.detach().numpy() for x,_ in clothing_images])\n",
        "y= np.array([y.detach().numpy() for _,y in clothing_images])\n",
        "\n",
        "\n",
        "\n",
        "X = X.reshape(X.shape[1]*X.shape[2]*X.shape[3],X.shape[0]).T\n",
        "y = y.reshape(y.shape[0],)\n",
        "\n",
        "X, y = shuffle(X, y, random_state=42)\n",
        "\n",
        "#print(X.shape)\n",
        "#print(y.shape)\n",
        "training_data, testing_data, training_labels, testing_labels = train_test_split(\n",
        " X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "\n",
        "# print(type(X))\n",
        "# print(\"x\",len(X))\n",
        "# print(\"y\", len(y))\n",
        "\n",
        "#dataloader_32 = torch.utils.data.DataLoader(clothing_images, batch_size=32, shuffle=True)\n",
        "\n",
        "# dataiter = iter(dataloader_32)\n",
        "# images, labels = dataiter.next()\n",
        "# images=images.numpy()\n",
        "\n",
        "# # Verification Step - obtain one batch of images\n",
        "# dataiter = iter(dataloader_32)\n",
        "# images, labels = dataiter.next()\n",
        "# images = images.numpy()\n",
        "# classes = ['T-shirt', 'Long Sleeve', 'Jeans', 'Lounge Pants', 'Shorts', 'Skirt', 'Sweater', 'Dress', 'Jacket']\n",
        "#  # plot the images in the batch, along with the corresponding labels\n",
        "# fig = plt.figure(figsize=(25, 4))\n",
        "# for idx in np.arange(20):\n",
        "#     ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "#     plt.imshow(images[idx])\n",
        "#     ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mInKBjmvv23",
        "outputId": "c5d06291-1d13-42a7-8624-06b44f9919c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Random Forest\n",
        "#Fereshteh\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#TUNE n_estimators\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "# Fit the model to our training data\n",
        "model.fit(training_data, training_labels)\n",
        "\n",
        "# Make predictions\n",
        "testing_predicted = model.predict(testing_data)\n",
        "print(\"testing_labels\",training_labels)\n",
        "print(\"testing_predicted\",testing_predicted )\n",
        "score=accuracy_score(testing_predicted,testing_labels)\n",
        "print(\"RF Test:\", score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "testing_labels [7 8 1 1 4 6 6 0 7 2 0 1 6 2 8 5 7 0 3 3 5 1 4 4 1 5 0 4 7 5 5 2 6 6 0 2 7\n",
            " 3 5 4 2 1 8 3 7 3 8 4]\n",
            "testing_predicted [5 6 7 6 6 0]\n",
            "RF Test: 0.16666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}