{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fnavab/APS360-project/blob/main/CNN_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mtc_bbbxWE_"
      },
      "source": [
        "#Network\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mgv2KU5xswJ"
      },
      "source": [
        "Visualize some of the data by running the code below. Include the visualization in your writeup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SX5wXnCGxvbf",
        "outputId": "7cea39fa-c39a-40d2-d669-c92b99c4401d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#mount googledrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgquoQ4wymER"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "use_cuda=True\n",
        "def get_data():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  #we might need to modify the transform\n",
        "  transform1 = transforms.Compose([transforms.Resize((224,224)), transforms.ToTensor()])\n",
        "  data_set=torchvision.datasets.ImageFolder('/content/drive/My Drive/aps360/Lab_3b_Gesture_Dataset', transform=transform1)\n",
        "\n",
        "  classes=data_set.classes\n",
        "  return classes, data_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uc0V66T0x2nE"
      },
      "source": [
        "Data Loading and Splitting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQGEtQiJy_71"
      },
      "source": [
        "# Prepare Dataloader\n",
        "def get_data_loader( classes , batchsize, dataset):\n",
        "  #data_loader = torch.utils.data.DataLoader(trainset, batch_size=batchsize, \n",
        "   #                                        num_workers=1, shuffle=True)\n",
        "\n",
        "  # indices=[] #create a list to store all indices\n",
        "  # for k in range(0,len(trainset)):\n",
        "  #   indices.append(k)\n",
        " \n",
        "  # Get the list of indices\n",
        "  indices = np.arange(len(dataset))\n",
        "\n",
        "\n",
        "\n",
        "# Split into train and validation  test\n",
        "  np.random.seed(20) # Fixed numpy random seed for reproducible shuffling\n",
        "  np.random.shuffle(indices)\n",
        "  split = int(len(indices) * 0.6) #split at 60%\n",
        "  split2=int(len(indices)*0.8)\n",
        "\n",
        "#  # split into training and validationand test indices\n",
        "  relevant_train_indices, relevant_val_indices  ,relevant_test_indices = indices[:split], indices[split:split2] , indices[split2:]\n",
        "  train_sampler = SubsetRandomSampler(relevant_train_indices)\n",
        "  train_loader = torch.utils.data.DataLoader(dataset, batch_size=batchsize)\n",
        "                                      \n",
        "  val_sampler = SubsetRandomSampler(relevant_val_indices)\n",
        "  val_loader = torch.utils.data.DataLoader(dataset, batch_size=batchsize,\n",
        "                                              num_workers=1, sampler=val_sampler)\n",
        "  # # Get the list of indices to sample from\n",
        "  \n",
        "  test_sampler = SubsetRandomSampler(relevant_test_indices)\n",
        "  test_loader = torch.utils.data.DataLoader(dataset, batch_size=batchsize,\n",
        "                                          num_workers=1, sampler=test_sampler)\n",
        "  \n",
        "  return train_loader, val_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgENMIR-30j-"
      },
      "source": [
        "# # Verification Step - obtain one batch of images\n",
        "def verify(data_loader,classes):\n",
        "  dataiter = iter(data_loader)\n",
        "  images, labels = dataiter.next()\n",
        "  images = images.numpy()\n",
        "  # plot the images in the batch, along with the corresponding labels\n",
        "  fig = plt.figure(figsize=(25, 4))\n",
        "  for idx in np.arange(20):\n",
        "      ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
        "      plt.imshow(np.transpose(images[idx], (1, 2, 0)))\n",
        "      ax.set_title(classes[labels[idx]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5MMgg2l6EAA"
      },
      "source": [
        "def save_features(data_loader,loader_name,feature_path, classes):\n",
        "  n = 0\n",
        "  for img, label in data_loader:\n",
        "    features = alexnet.features(img)\n",
        "    features_tensor = torch.from_numpy(features.detach().numpy())\n",
        "    folder_name = feature_path + '/' +loader_name+'/'+ str(classes[label])\n",
        "    if not os.path.isdir(folder_name):\n",
        "      os.mkdir(folder_name)\n",
        "    torch.save(features_tensor.squeeze(0), folder_name + '/' + str(n) + '.tensor')\n",
        "    n += 1\n",
        "  print(folder_name,\"features saved\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iLgYmpa45AO",
        "outputId": "b2814d44-0140-48c5-8e7a-938d5ec5252f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torchvision.models\n",
        "import os\n",
        "alexnet = torchvision.models.alexnet(pretrained=True)\n",
        "\n",
        "# initialize path\n",
        "\n",
        "feature_path = '/content/drive/My Drive/aps360/Lab3/Lab3_Data/Features'\n",
        "# Prepare Dataloader \n",
        "classes1, dataset= get_data()\n",
        "train_loader, val_loader, test_loader=get_data_loader(classes=classes1, batchsize=1, dataset=dataset)\n",
        "\n",
        "save_features(train_loader,\"train\",feature_path, classes=classes1)\n",
        "save_features(val_loader,\"val\",feature_path, classes=classes1)\n",
        "save_features(test_loader,\"test\",feature_path, classes=classes1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/aps360/Lab3/Lab3_Data/Features/train/I features saved\n",
            "/content/drive/My Drive/aps360/Lab3/Lab3_Data/Features/val/F features saved\n",
            "/content/drive/My Drive/aps360/Lab3/Lab3_Data/Features/test/D features saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4VCtQnKP8IxH"
      },
      "source": [
        "def get_alex_data_loader(batch_size):\n",
        "  train_dir = '/content/drive/My Drive/aps360/Lab3/Lab3_Data/Features/train'\n",
        "  test_dir = '/content/drive/My Drive/aps360/Lab3/Lab3_Data/Features/test'\n",
        "  val_dir = '/content/drive/My Drive/aps360/Lab3/Lab3_Data/Features/val'\n",
        "  train_set = torchvision.datasets.DatasetFolder(train_dir, loader=torch.load, extensions=('.tensor'))\n",
        "  val_set= torchvision.datasets.DatasetFolder(val_dir, loader=torch.load, extensions=('.tensor'))\n",
        "  test_set = torchvision.datasets.DatasetFolder(test_dir, loader=torch.load, extensions=('.tensor'))\n",
        "  torch.manual_seed(1) # set the random seed\n",
        "\n",
        "  num_workers = 1\n",
        "  train_feature_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, \n",
        "                                            num_workers=num_workers, shuffle=True)\n",
        "  test_feature_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, \n",
        "                                            num_workers=num_workers, shuffle=True)\n",
        "  val_feature_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, \n",
        "                                            num_workers=num_workers, shuffle=True)\n",
        "\n",
        "\n",
        "  return train_feature_loader, test_feature_loader,val_feature_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8uFWWY_N71cA"
      },
      "source": [
        "#modify batch size\n",
        "train_feature_loader, test_feature_loader,val_feature_loader=get_alex_data_loader(64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4jinHsZ9NhM",
        "outputId": "e658f052-012d-4e70-d761-08bd63bd23d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Verification Step - obtain one batch of features\n",
        "dataiter = iter(val_feature_loader)\n",
        "features, labels = dataiter.next()\n",
        "print(features.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([64, 256, 6, 6])\n",
            "torch.Size([64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYrbCjmz9T7S"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Modify\n",
        "class CNN_ALEX(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_ALEX, self).__init__()\n",
        "        self.name=\"CNN_ALEX\"\n",
        "        self.conv = nn.Conv2d(256, 10, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        self.fc1 = nn.Linear(10* 2* 2, 32)\n",
        "        self.fc2 = nn.Linear(32, 9)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv(x)))\n",
        "        x = x.view(x.shape[0], 10* 2* 2) #flatten feature data\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        x = x.squeeze(1)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUOpojpBAgrp"
      },
      "source": [
        "def get_model_name(name, batch_size, learning_rate, epoch):\n",
        "    \"\"\" Generate a name for the model consisting of all the hyperparameter values\n",
        "\n",
        "    Args:\n",
        "        config: Configuration object containing the hyperparameters\n",
        "    Returns:\n",
        "        path: A string with the hyperparameter name and value concatenated\n",
        "    \"\"\"\n",
        "    path = \"model_{0}_bs{1}_lr{2}_epoch{3}\".format(name,\n",
        "                                                   batch_size,\n",
        "                                                   learning_rate,\n",
        "                                                   epoch)\n",
        "    return path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghv1NwUMAeEo"
      },
      "source": [
        "def get_accuracy(model, data_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for imgs, labels in data_loader:\n",
        "        \n",
        "        if use_cuda and torch.cuda.is_available():\n",
        "          imgs = imgs.cuda()\n",
        "          labels = labels.cuda()\n",
        "\n",
        "        output = model(imgs)\n",
        "        #select index with maximum prediction score\n",
        "        pred = output.max(1, keepdim=True)[1]\n",
        "        correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "        total += imgs.shape[0]\n",
        "    return correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJFaKr-k-ZH3"
      },
      "source": [
        "def train_net(model,target_classes,train_loader,val_loader, batch_size=64, learn_rate=0.001, num_epochs=30):\n",
        "    ########################################################################\n",
        "    ########################################################################\n",
        "    # Fixed PyTorch random seed for reproducible result\n",
        "    torch.manual_seed(1000)\n",
        "    ########################################################################\n",
        "    ########################################################################\n",
        "    # Define the Loss function and optimizer\n",
        "    # The loss function will be Cross Entropy,which will apply softmax to the output layer\n",
        "    # Optimizer will be SGD with Momentum.\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learn_rate)\n",
        "\n",
        "    ########################################################################\n",
        "    # Set up some numpy arrays to store the training/test loss/erruracy\n",
        "    train_acc = np.zeros(num_epochs)\n",
        "    train_loss = np.zeros(num_epochs)\n",
        "    val_acc = np.zeros(num_epochs)\n",
        "    val_loss = np.zeros(num_epochs)\n",
        "    ########################################################################\n",
        "    # Train the network\n",
        "    # Loop over the data iterator and sample a new batch of training data\n",
        "    # Get the output from the network, and optimize our loss function.\n",
        "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "        total_train_loss = 0.0\n",
        "        total_train_acc = 0.0\n",
        "        total_epoch = 0\n",
        "        for imgs, labels in iter(train_loader):\n",
        "\n",
        "            if use_cuda and torch.cuda.is_available():\n",
        "              imgs = imgs.cuda()\n",
        "              labels = labels.cuda()\n",
        "\n",
        "            # Forward pass, backward pass, and optimize\n",
        "            outputs = model(imgs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()         # a clean up step for PyTorch\n",
        "\n",
        "            # Calculate the statistics\n",
        "            total_train_loss += loss.item()\n",
        "            total_epoch += len(labels)\n",
        "        train_loss[epoch] = float(total_train_loss) / (batch_size)\n",
        "        train_acc[epoch]= get_accuracy(model, train_loader)\n",
        "        val_acc[epoch] = get_accuracy(model, val_loader)\n",
        "        print((\"Epoch {}: Train acc: {}, Train loss: {} |\"+\n",
        "               \"Validation acc: {}\").format(\n",
        "                   epoch + 1,\n",
        "                   train_acc[epoch],\n",
        "                   train_loss[epoch],\n",
        "                   val_acc[epoch]\n",
        "                   ))\n",
        "        # Save the current model (checkpoint) to a file\n",
        "        model_path = get_model_name(model.name, batch_size, learn_rate, epoch)\n",
        "        torch.save(model.state_dict(), model_path)\n",
        "    print('Finished Training')\n",
        "\n",
        "    # Write the train/test loss/err into CSV file \n",
        "    epochs = np.arange(1, num_epochs + 1)\n",
        "    np.savetxt(\"{}_train_acc.csv\".format(model_path), train_acc)\n",
        "    np.savetxt(\"{}_train_loss.csv\".format(model_path), train_loss)\n",
        "    np.savetxt(\"{}_val_acc.csv\".format(model_path), val_acc)\n",
        "\n",
        "\n",
        "    print(\"Final Training Accuracy: {}\".format(train_acc[-1]))\n",
        "    print(\"Final Validation Accuracy: {}\".format(val_acc[-1]))\n",
        "\n",
        "    # plotting\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, train_loss, label=\"Train\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.show()\n",
        "\n",
        "    plt.title(\"Training Curve\")\n",
        "    plt.plot(epochs, train_acc, label=\"Train\")\n",
        "    plt.plot(epochs, val_acc, label=\"Validation\")\n",
        "    plt.xlabel(\"Iterations\")\n",
        "    plt.ylabel(\"Training Accuracy\")\n",
        "    plt.legend(loc='best')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EB6TWpTpBWVj"
      },
      "source": [
        "Hyper parameter tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ok9kNotIBQz4",
        "outputId": "13930e27-1bb6-4030-eb80-dd9ab49d2dd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "use_cuda = True\n",
        "\n",
        "model=CNN_ALEX()\n",
        "#Modify\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "    model.cuda()\n",
        "train_net(model, classes1,train_feature_loader, val_feature_loader, batch_size=64, num_epochs=20, learn_rate = 0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: Train acc: 0.6540518305224188, Train loss: 1.0324055682867765 |Validation acc: 0.6646090534979424\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}